{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scikitplot\n",
    "import random\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from keras.models import Model\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from keras.regularizers import l1, l2\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images collected: 182\n",
      "Total test images collected: 70\n",
      "Total validation images collected: 14\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the root folder\n",
    "train_path = 'images/emotions_dataset/train/'\n",
    "test_path = 'images/emotions_dataset/test/'\n",
    "val_path = 'images/emotions_dataset/validation/'\n",
    "\n",
    "\n",
    "def read_images(path):\n",
    "\n",
    "    # Initialize a list to store image data as tuples\n",
    "    image_data = []\n",
    "\n",
    "    # Create a mapping from string labels (emotions) to class numbers\n",
    "    emotion_to_class = {'anger': 1, 'fear': 2, 'happiness': 3, 'sadness': 4, 'surprise': 5, 'neutral': 6, 'disgust': 7}\n",
    "\n",
    "    # Loop through the subfolders\n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for image_name in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image_name)\n",
    "                if os.path.isfile(image_path) and not image_path.lower().endswith(('.heic', '.HEIC')):\n",
    "                    # Read the image\n",
    "                    image = cv2.imread(image_path)                \n",
    "                    # Extract emotion label from the image name\n",
    "                    emotion_label = os.path.splitext(image_name)[0]\n",
    "                    if emotion_label== \"surprised\":\n",
    "                        emotion_label= 'surprise'\n",
    "                    if emotion_label== \"sad\":\n",
    "                        emotion_label= 'sadness'\n",
    "                    # Convert the emotion label to class number using the mapping\n",
    "                    class_number = emotion_to_class.get(emotion_label.lower(), -1)  # -1 as a default value if the label is not in the mapping\n",
    "                    \n",
    "                    # Store image and label as a tuple in the list\n",
    "                    image_data.append((image, class_number))\n",
    "    \n",
    "    return image_data\n",
    "\n",
    "\n",
    "train_data = read_images(train_path)\n",
    "test_data = read_images(test_path)\n",
    "val_data = read_images(val_path)\n",
    "\n",
    "# Display the length of the collected image data\n",
    "print(\"Total train images collected:\", len(train_data))\n",
    "print(\"Total test images collected:\", len(test_data))\n",
    "print(\"Total validation images collected:\", len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Save images to the main directory \"shuffled data with labels\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m save_images(train_data, train_output_dir)\n\u001b[1;32m---> 28\u001b[0m \u001b[43msave_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_output_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m save_images(val_data, val_output_dir)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36msave_images\u001b[1;34m(data, directory)\u001b[0m\n\u001b[0;32m     22\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000000\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Random filename to prevent conflicts\u001b[39;00m\n\u001b[0;32m     23\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(emotion_dir, filename)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the output directory\n",
    "train_output_dir = 'images/shuffled/shuffled train data with labels'\n",
    "\n",
    "test_output_dir = 'images/shuffled/shuffled test data with labels'\n",
    "\n",
    "val_output_dir = 'images/shuffled/shuffled val data with labels'\n",
    "\n",
    "# Create a mapping from class numbers to string labels (emotions)\n",
    "class_to_emotion = {1:'anger', 2:'fear', 3:'happiness',  4:'sadness',  5:'surprise',  6:'neutral', 7:'disgust'}\n",
    "\n",
    "# Function to save images to directories\n",
    "def save_images(data, directory):\n",
    "    for image, emotion in data:\n",
    "        # Convert class number to emotion label\n",
    "        emotion_label = class_to_emotion.get(emotion, 'Unknown')\n",
    "        \n",
    "        # Create directories based on emotion labels in the output directory\n",
    "        emotion_dir = os.path.join(directory, emotion_label)\n",
    "        os.makedirs(emotion_dir, exist_ok=True)\n",
    "\n",
    "        # Save images to respective emotion directories\n",
    "        filename = f\"{random.randint(0, 1000000)}.jpg\"  # Random filename to prevent conflicts\n",
    "        image_path = os.path.join(emotion_dir, filename)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "# Save images to the main directory \"shuffled data with labels\"\n",
    "save_images(train_data, train_output_dir)\n",
    "save_images(test_data, test_output_dir)\n",
    "save_images(val_data, val_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def detect_and_save_faces(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize the face detector and landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    # Loop over the images in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Read the image\n",
    "            img = cv2.imread(image_path)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect faces in the image\n",
    "            faces = detector(gray)\n",
    "\n",
    "            # Loop over the faces and save the extracted faces\n",
    "            for face in faces:\n",
    "                landmarks = predictor(gray, face)\n",
    "\n",
    "                # Draw a rectangle around the face\n",
    "                cv2.rectangle(img, (face.left(), face.top()), (face.right(), face.bottom()), (0, 255, 0), 2)\n",
    "\n",
    "                # Save the extracted face without landmarks\n",
    "                extracted_face = img[face.top():face.bottom(), face.left():face.right()]\n",
    "                cv2.imwrite(os.path.join(output_folder, f\"{filename}_face.jpg\"), extracted_face)\n",
    "\n",
    "    # Count the number of extracted faces\n",
    "    num_faces = len(os.listdir(output_folder))\n",
    "    print(f\"Total number of extracted faces: {num_faces}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extracted faces: 25\n",
      "Total number of extracted faces: 26\n",
      "Total number of extracted faces: 26\n",
      "Total number of extracted faces: 26\n",
      "Total number of extracted faces: 26\n",
      "Total number of extracted faces: 26\n",
      "Total number of extracted faces: 26\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the root folder containing emotion folders\n",
    "root_folder_path = 'images/shuffled/shuffled train data with labels'\n",
    "\n",
    "# Loop through each folder of emotions\n",
    "for folder_name in os.listdir(root_folder_path):\n",
    "    folder_path = os.path.join(root_folder_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Define input and output folders for each emotion\n",
    "        input_folder = folder_path\n",
    "        output_folder = os.path.join('images/detected faces/train detected faces for each emotion', folder_name)\n",
    "\n",
    "        # Detect and save faces for the current emotion folder\n",
    "        detect_and_save_faces(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extracted faces: 10\n",
      "Total number of extracted faces: 10\n",
      "Total number of extracted faces: 10\n",
      "Total number of extracted faces: 10\n",
      "Total number of extracted faces: 10\n",
      "Total number of extracted faces: 10\n",
      "Total number of extracted faces: 10\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the root folder containing emotion folders\n",
    "root_folder_path = 'images/shuffled/shuffled test data with labels'\n",
    "\n",
    "# Loop through each folder of emotions\n",
    "for folder_name in os.listdir(root_folder_path):\n",
    "    folder_path = os.path.join(root_folder_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Define input and output folders for each emotion\n",
    "        input_folder = folder_path\n",
    "        output_folder = os.path.join('images/detected faces/test data detected faces for each emotion', folder_name)\n",
    "\n",
    "        # Detect and save faces for the current emotion folder\n",
    "        detect_and_save_faces(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extracted faces: 2\n",
      "Total number of extracted faces: 2\n",
      "Total number of extracted faces: 2\n",
      "Total number of extracted faces: 2\n",
      "Total number of extracted faces: 2\n",
      "Total number of extracted faces: 2\n",
      "Total number of extracted faces: 2\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the root folder containing emotion folders\n",
    "root_folder_path = 'images/shuffled/shuffled val data with labels'\n",
    "\n",
    "# Loop through each folder of emotions\n",
    "for folder_name in os.listdir(root_folder_path):\n",
    "    folder_path = os.path.join(root_folder_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Define input and output folders for each emotion\n",
    "        input_folder = folder_path\n",
    "        output_folder = os.path.join('images/detected faces/validation detected faces for each emotion', folder_name)\n",
    "\n",
    "        # Detect and save faces for the current emotion folder\n",
    "        detect_and_save_faces(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(root_folder, target_size):\n",
    "    # Get the list of emotions (subfolder names) within the root folder\n",
    "    emotions = [emotion for emotion in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, emotion))]\n",
    "\n",
    "    # Create the 'preprocessed' directory to save processed images\n",
    "    preprocessed_root = os.path.join(root_folder, 'preprocessed')\n",
    "    os.makedirs(preprocessed_root, exist_ok=True)\n",
    "\n",
    "    # Loop through each emotion folder\n",
    "    for emotion in emotions:\n",
    "        emotion_folder = os.path.join(root_folder, emotion)\n",
    "        preprocessed_emotion_folder = os.path.join(preprocessed_root, emotion)\n",
    "        os.makedirs(preprocessed_emotion_folder, exist_ok=True)\n",
    "\n",
    "        # Get the list of image files in the emotion folder\n",
    "        image_files = [file for file in os.listdir(emotion_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        # Preprocess each image in the emotion folder\n",
    "        for image_file in image_files:\n",
    "            img_path = os.path.join(emotion_folder, image_file)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is not None:\n",
    "                # Resize the image\n",
    "                img_resized = cv2.resize(img, target_size)\n",
    "\n",
    "                # Convert the image to grayscale\n",
    "                img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Save the preprocessed image in the preprocessed emotion folder\n",
    "                new_img_path = os.path.join(preprocessed_emotion_folder, image_file)\n",
    "                cv2.imwrite(new_img_path, img_gray)\n",
    "            else:\n",
    "                print(f\"Unable to read image: {image_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_directory = 'images/detected faces/train detected faces for each emotion'\n",
    "test_root_directory = 'images/detected faces/test detected faces for each emotion'\n",
    "val_root_directory = 'images/detected faces/validation detected faces for each emotion'\n",
    "target_size = (128, 128)\n",
    "preprocess_images(train_root_directory, target_size)\n",
    "preprocess_images(test_root_directory, target_size)\n",
    "preprocess_images(val_root_directory, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(input_folder, output_folder, target_num_images):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # List all files in the input folder\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "\n",
    "    # Check if there are enough images for augmentation\n",
    "    if len(image_files) == 0:\n",
    "        print(\"No images found in the input folder.\")\n",
    "        return\n",
    "\n",
    "    # Calculate the number of augmentations needed per image\n",
    "    augmentations_per_image = max(target_num_images // len(image_files), 1)\n",
    "\n",
    "    # Keep augmenting until the desired number is reached\n",
    "    augmented_images = []\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Read the original image\n",
    "        img = cv2.imread(os.path.join(input_folder, image_file))\n",
    "\n",
    "        for j in range(augmentations_per_image):\n",
    "            # Perform augmentations\n",
    "            flipped_horizontally = cv2.flip(img, 1)\n",
    "            flipped_hf = cv2.flip(flipped_horizontally, 1)\n",
    "            # Rotate 30 degrees to the left\n",
    "            rotation_matrix_left = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), 30, 1)\n",
    "            rotated_left = cv2.warpAffine(img, rotation_matrix_left, (img.shape[1], img.shape[0]))\n",
    "\n",
    "            # Rotate 30 degrees to the right\n",
    "            rotation_matrix_right = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), -30, 1)\n",
    "            rotated_right = cv2.warpAffine(img, rotation_matrix_right, (img.shape[1], img.shape[0]))\n",
    "\n",
    "            # Rotate 15 degrees to the left\n",
    "            rotation_matrix_left_15 = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), 15, 1)\n",
    "            rotated_left_15 = cv2.warpAffine(img, rotation_matrix_left_15, (img.shape[1], img.shape[0]))\n",
    "\n",
    "            # Rotate 15 degrees to the right\n",
    "            rotation_matrix_right_15 = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), -15, 1)\n",
    "            rotated_right_15 = cv2.warpAffine(img, rotation_matrix_right_15, (img.shape[1], img.shape[0]))\n",
    "\n",
    "\n",
    "            # Add augmented images to the list\n",
    "            augmented_images.extend([\n",
    "                flipped_horizontally, flipped_hf,rotated_left,rotated_right,rotated_left_15,rotated_right_15\n",
    "            ])\n",
    "\n",
    "    # Randomly shuffle the augmented images\n",
    "    #random.shuffle(augmented_images)\n",
    "\n",
    "    # Save only the required number of images\n",
    "    for i, augmented_image in enumerate(augmented_images[:target_num_images]):\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{i}_augmented.jpg\"), augmented_image)\n",
    "\n",
    "    print(f\"{target_num_images} images requested, {len(augmented_images)} images augmented and saved to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 images requested, 960 images augmented and saved to images/Augmentation/test/sadness\n"
     ]
    }
   ],
   "source": [
    "train_input_folder = \"images/detected faces/train detected faces for each emotion/preprocessed/surprise\"\n",
    "train_output_folder = \"images/Augmentation/train/surprise\"\n",
    "test_input_folder = \"images/detected faces/test detected faces for each emotion/preprocessed/surprise\"\n",
    "test_output_folder = \"images/Augmentation/test/surprise\"\n",
    "train_target_num_images = 416\n",
    "test_target_num_images = 160\n",
    "\n",
    "augment_images(train_input_folder, train_output_folder, train_target_num_images)\n",
    "augment_images(test_input_folder, test_output_folder, test_target_num_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
